{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install setuptools==58.2.0\n",
    "#pip install scikit-surprise==1.1.3\n",
    "#pip install mlxtend\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import heapq\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "from surprise import dataset, Reader\n",
    "from surprise.prediction_algorithms import KNNBasic\n",
    "from surprise.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = Path('dmba')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Identifying Course Combinations. The Institute for Statistics Education at Statistics.com offers online courses in statistics and analytics, and is seeking information that will help in packaging and sequencing courses. Consider the data in the file CourseTopics.csv, the first few rows of which are shown in Table 14.14. These data are for purchases of online statistics courses at Statistics.com. Each row represents the courses attended by a single customer. The firm wishes to assess alternative sequencings and bundling of courses. Use association rules to analyze these data, and interpret several of the resulting rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Intro  DataMining  Survey  Cat Data  Regression  Forecast  DOE  SW\n",
      "0      1           1       0         0           0         0    0   0\n",
      "1      0           0       1         0           0         0    0   0\n",
      "2      0           1       0         1           1         0    0   1\n",
      "3      1           0       0         0           0         0    0   0\n",
      "4      1           1       0         0           0         0    0   0\n"
     ]
    }
   ],
   "source": [
    "ct_df = pd.read_csv(DATA / 'CourseTopics.csv')\n",
    "print(ct_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_bool = pd.get_dummies(ct_df, prefix_sep='_', drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intro         bool\n",
       "DataMining    bool\n",
       "Survey        bool\n",
       "Cat Data      bool\n",
       "Regression    bool\n",
       "Forecast      bool\n",
       "DOE           bool\n",
       "SW            bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in ct_df.columns:\n",
    "    ct_df[i] = ct_df[i].astype('bool')\n",
    "\n",
    "ct_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemsets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.394521</td>\n",
       "      <td>(Intro)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.178082</td>\n",
       "      <td>(DataMining)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.186301</td>\n",
       "      <td>(Survey)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.208219</td>\n",
       "      <td>(Cat Data)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.208219</td>\n",
       "      <td>(Regression)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.139726</td>\n",
       "      <td>(Forecast)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.172603</td>\n",
       "      <td>(DOE)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.221918</td>\n",
       "      <td>(SW)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.054795</td>\n",
       "      <td>(Intro, DataMining)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.060274</td>\n",
       "      <td>(Survey, Intro)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.071233</td>\n",
       "      <td>(Cat Data, Intro)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.071233</td>\n",
       "      <td>(Intro, Regression)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.052055</td>\n",
       "      <td>(Intro, Forecast)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.095890</td>\n",
       "      <td>(SW, Intro)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.063014</td>\n",
       "      <td>(Cat Data, Survey)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.054795</td>\n",
       "      <td>(Cat Data, Regression)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.063014</td>\n",
       "      <td>(Cat Data, SW)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.054795</td>\n",
       "      <td>(SW, Regression)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.057534</td>\n",
       "      <td>(SW, DOE)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     support                itemsets\n",
       "0   0.394521                 (Intro)\n",
       "1   0.178082            (DataMining)\n",
       "2   0.186301                (Survey)\n",
       "3   0.208219              (Cat Data)\n",
       "4   0.208219            (Regression)\n",
       "5   0.139726              (Forecast)\n",
       "6   0.172603                   (DOE)\n",
       "7   0.221918                    (SW)\n",
       "8   0.054795     (Intro, DataMining)\n",
       "9   0.060274         (Survey, Intro)\n",
       "10  0.071233       (Cat Data, Intro)\n",
       "11  0.071233     (Intro, Regression)\n",
       "12  0.052055       (Intro, Forecast)\n",
       "13  0.095890             (SW, Intro)\n",
       "14  0.063014      (Cat Data, Survey)\n",
       "15  0.054795  (Cat Data, Regression)\n",
       "16  0.063014          (Cat Data, SW)\n",
       "17  0.054795        (SW, Regression)\n",
       "18  0.057534               (SW, DOE)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create frequent itemsets\n",
    "itemsets = apriori(ct_df, min_support=0.05, use_colnames=True)\n",
    "itemsets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "      <th>zhangs_metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(Survey)</td>\n",
       "      <td>(Cat Data)</td>\n",
       "      <td>0.186301</td>\n",
       "      <td>0.208219</td>\n",
       "      <td>0.063014</td>\n",
       "      <td>0.338235</td>\n",
       "      <td>1.624420</td>\n",
       "      <td>0.024222</td>\n",
       "      <td>1.196469</td>\n",
       "      <td>0.472405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(Cat Data)</td>\n",
       "      <td>(Survey)</td>\n",
       "      <td>0.208219</td>\n",
       "      <td>0.186301</td>\n",
       "      <td>0.063014</td>\n",
       "      <td>0.302632</td>\n",
       "      <td>1.624420</td>\n",
       "      <td>0.024222</td>\n",
       "      <td>1.166813</td>\n",
       "      <td>0.485482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(DOE)</td>\n",
       "      <td>(SW)</td>\n",
       "      <td>0.172603</td>\n",
       "      <td>0.221918</td>\n",
       "      <td>0.057534</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.502058</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>1.167123</td>\n",
       "      <td>0.403974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(Cat Data)</td>\n",
       "      <td>(SW)</td>\n",
       "      <td>0.208219</td>\n",
       "      <td>0.221918</td>\n",
       "      <td>0.063014</td>\n",
       "      <td>0.302632</td>\n",
       "      <td>1.363710</td>\n",
       "      <td>0.016806</td>\n",
       "      <td>1.115741</td>\n",
       "      <td>0.336844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(SW)</td>\n",
       "      <td>(Intro)</td>\n",
       "      <td>0.221918</td>\n",
       "      <td>0.394521</td>\n",
       "      <td>0.095890</td>\n",
       "      <td>0.432099</td>\n",
       "      <td>1.095250</td>\n",
       "      <td>0.008339</td>\n",
       "      <td>1.066170</td>\n",
       "      <td>0.111771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Forecast)</td>\n",
       "      <td>(Intro)</td>\n",
       "      <td>0.139726</td>\n",
       "      <td>0.394521</td>\n",
       "      <td>0.052055</td>\n",
       "      <td>0.372549</td>\n",
       "      <td>0.944308</td>\n",
       "      <td>-0.003070</td>\n",
       "      <td>0.964983</td>\n",
       "      <td>-0.064157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  antecedents consequents  antecedent support  consequent support   support  \\\n",
       "7    (Survey)  (Cat Data)            0.186301            0.208219  0.063014   \n",
       "6  (Cat Data)    (Survey)            0.208219            0.186301  0.063014   \n",
       "9       (DOE)        (SW)            0.172603            0.221918  0.057534   \n",
       "8  (Cat Data)        (SW)            0.208219            0.221918  0.063014   \n",
       "5        (SW)     (Intro)            0.221918            0.394521  0.095890   \n",
       "4  (Forecast)     (Intro)            0.139726            0.394521  0.052055   \n",
       "\n",
       "   confidence      lift  leverage  conviction  zhangs_metric  \n",
       "7    0.338235  1.624420  0.024222    1.196469       0.472405  \n",
       "6    0.302632  1.624420  0.024222    1.166813       0.485482  \n",
       "9    0.333333  1.502058  0.019231    1.167123       0.403974  \n",
       "8    0.302632  1.363710  0.016806    1.115741       0.336844  \n",
       "5    0.432099  1.095250  0.008339    1.066170       0.111771  \n",
       "4    0.372549  0.944308 -0.003070    0.964983      -0.064157  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and convert into rules\n",
    "rules = association_rules(itemsets, metric='confidence', min_threshold=0.3)\n",
    "rules.sort_values(by=['lift'], ascending=False).head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a customer buys Survey they are 1.6 times as likley to buy Cat Data and vice versa. If a customer buys DOE they are 1.5 times as likley to buy SW. A customer buying CAT data is 1.1 times as likely to buy SW, and a customer buying SW is 1.1 times as likely to buy intro. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Cosmetics Purchases. The data shown in Table 14.15 and the output in Table 14.16 are based on a subset of a dataset on cosmetic purchases (Cosmetics.csv) at a large chain drugstore. The store wants to analyze associations among purchases of these items for purposes of point-of-sale display, guidance to sales personnel in promoting cross-sales, and guidance for piloting an eventual time-of- purchase electronic recommender system to boost cross-sales. Consider first only the data shown in Table 14.15, given in binary matrix form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Select several values in the matrix and explain their meaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A 1 in the table means they have bought the item, a zero means they did not. Then we look at the column names for the item type that has either been bought nor not. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Consider the results of the association rules analysis shown in Table 14.16."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### i. For the first row, explain the “confidence” output and how it is calculated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the confidence out put is the ratio of number of transactions that include all antecedent and consequent itemsets (namely, the support) to the number of transactions that include all the antecedent itemsets. \n",
    "\n",
    "Vaguely calculated as follows :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "confidence = (number of transactions that include all antecedent and consequent itemsets) / (number of transactions that include all the antecedent itemsets. )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  ii. For the first row, explain the “support” output and how it is calculated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "support is simply the number of transactions that include both the antecedent and consequent itemsets. \n",
    "\n",
    "Calculated as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "support = (number of transactions that include both the antecedent and consequent itemsets)/ (the total number of records in the database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  iii. For the first row, explain the “lift” and how it is calculated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a ratio that is the confidence of the rule divided by the benchmark confidence\n",
    "\n",
    "calcualted as follows: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lift = (Confidence)/(benchmark confidenece)\n",
    "\n",
    "with\n",
    "\n",
    "benchmark confidenece = (number of transactions with consequent itemsets)/ (the total number of transactions in the database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  iv. For the first row, explain the rule that is represented there in words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the customer buys (blush, concealer, mascara, eye shadow, and lipstick), then we can say that with a 30% level of confidence that they are 7.19823 times as likley to buy Eyebrow pencils. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Now, use the complete dataset on the cosmetics purchases (in the file Cosmetics.csv). Using Python, apply association rules to these data (for apriori use min_support=0.1 and use_colnames=True, for association_rules use default parameters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Trans.   Bag  Blush  Nail Polish  Brushes  Concealer  Eyebrow Pencils  \\\n",
      "0        1    0      1            1        1          1                0   \n",
      "1        2    0      0            1        0          1                0   \n",
      "2        3    0      1            0        0          1                1   \n",
      "3        4    0      0            1        1          1                0   \n",
      "4        5    0      1            0        0          1                0   \n",
      "\n",
      "   Bronzer  Lip liner  Mascara  Eye shadow  Foundation  Lip Gloss  Lipstick  \\\n",
      "0        1          1        1           0           0          0         0   \n",
      "1        1          1        0           0           1          1         0   \n",
      "2        1          1        1           1           1          1         1   \n",
      "3        1          0        0           0           1          0         0   \n",
      "4        1          1        1           1           0          1         1   \n",
      "\n",
      "   Eyeliner  \n",
      "0         1  \n",
      "1         0  \n",
      "2         0  \n",
      "3         1  \n",
      "4         0  \n"
     ]
    }
   ],
   "source": [
    "cm_df = pd.read_csv(DATA / 'Cosmetics.csv')\n",
    "print(cm_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Bag  Blush  Nail Polish  Brushes  Concealer  Eyebrow Pencils  \\\n",
      "Trans.                                                                  \n",
      "1          0      1            1        1          1                0   \n",
      "2          0      0            1        0          1                0   \n",
      "3          0      1            0        0          1                1   \n",
      "\n",
      "         Bronzer  Lip liner  Mascara  Eye shadow  Foundation  Lip Gloss  \\\n",
      "Trans.                                                                    \n",
      "1              1          1        1           0           0          0   \n",
      "2              1          1        0           0           1          1   \n",
      "3              1          1        1           1           1          1   \n",
      "\n",
      "         Lipstick  Eyeliner  \n",
      "Trans.                       \n",
      "1               0         1  \n",
      "2               0         0  \n",
      "3               1         0  \n"
     ]
    }
   ],
   "source": [
    "cm_df.set_index('Trans. ', inplace=True)\n",
    "print(cm_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tanve\\AppData\\Roaming\\Python\\Python310\\site-packages\\mlxtend\\frequent_patterns\\fpcommon.py:110: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# create frequent itemsets\n",
    "itemsets = apriori(cm_df, min_support=0.1, use_colnames=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and convert into rules\n",
    "rules = association_rules(itemsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i. Interpret the first three rules in the output in words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "      <th>zhangs_metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Brushes)</td>\n",
       "      <td>(Nail Polish)</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.149</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>0.107280</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.846063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(Blush, Concealer, Eye shadow)</td>\n",
       "      <td>(Mascara)</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.959677</td>\n",
       "      <td>2.688172</td>\n",
       "      <td>0.074732</td>\n",
       "      <td>15.9464</td>\n",
       "      <td>0.716895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(Blush, Eye shadow)</td>\n",
       "      <td>(Mascara)</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>2.601040</td>\n",
       "      <td>0.104026</td>\n",
       "      <td>9.0020</td>\n",
       "      <td>0.752492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       antecedents    consequents  antecedent support  \\\n",
       "0                        (Brushes)  (Nail Polish)               0.149   \n",
       "22  (Blush, Concealer, Eye shadow)      (Mascara)               0.124   \n",
       "5              (Blush, Eye shadow)      (Mascara)               0.182   \n",
       "\n",
       "    consequent support  support  confidence      lift  leverage  conviction  \\\n",
       "0                0.280    0.149    1.000000  3.571429  0.107280         inf   \n",
       "22               0.357    0.119    0.959677  2.688172  0.074732     15.9464   \n",
       "5                0.357    0.169    0.928571  2.601040  0.104026      9.0020   \n",
       "\n",
       "    zhangs_metric  \n",
       "0        0.846063  \n",
       "22       0.716895  \n",
       "5        0.752492  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules.sort_values(by=['lift'], ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If someone buys Brushes, then they are 3.57 times as likely to buy nail polish.\n",
    "If someone buys Blush, concealer, and eye shadow, we can say with 95% confidence that they are 2.69 times as likley to buy mascara; but if they dont buy concealer, then we can say with 93% confidence that they are only 2.6 times as likley to buy mascara.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii. Reviewing the first couple of dozen rules, comment on their redundancy and how you would assess their utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "      <th>zhangs_metric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Brushes)</td>\n",
       "      <td>(Nail Polish)</td>\n",
       "      <td>0.149</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.149</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.571429</td>\n",
       "      <td>0.107280</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.846063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>(Blush, Concealer, Eye shadow)</td>\n",
       "      <td>(Mascara)</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.959677</td>\n",
       "      <td>2.688172</td>\n",
       "      <td>0.074732</td>\n",
       "      <td>15.946400</td>\n",
       "      <td>0.716895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(Blush, Eye shadow)</td>\n",
       "      <td>(Mascara)</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>2.601040</td>\n",
       "      <td>0.104026</td>\n",
       "      <td>9.002000</td>\n",
       "      <td>0.752492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(Nail Polish, Eye shadow)</td>\n",
       "      <td>(Mascara)</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.908397</td>\n",
       "      <td>2.544529</td>\n",
       "      <td>0.072233</td>\n",
       "      <td>7.019417</td>\n",
       "      <td>0.698504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(Concealer, Eye shadow)</td>\n",
       "      <td>(Mascara)</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.890547</td>\n",
       "      <td>2.494530</td>\n",
       "      <td>0.107243</td>\n",
       "      <td>5.874682</td>\n",
       "      <td>0.749841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(Bronzer, Eye shadow)</td>\n",
       "      <td>(Mascara)</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.879433</td>\n",
       "      <td>2.463397</td>\n",
       "      <td>0.073663</td>\n",
       "      <td>5.333118</td>\n",
       "      <td>0.691567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(Concealer, Eye shadow, Eyeliner)</td>\n",
       "      <td>(Mascara)</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.876923</td>\n",
       "      <td>2.456367</td>\n",
       "      <td>0.067590</td>\n",
       "      <td>5.224375</td>\n",
       "      <td>0.681488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Blush, Mascara)</td>\n",
       "      <td>(Eye shadow)</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.918478</td>\n",
       "      <td>2.410704</td>\n",
       "      <td>0.098896</td>\n",
       "      <td>7.593067</td>\n",
       "      <td>0.717137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>(Lipstick, Eye shadow)</td>\n",
       "      <td>(Mascara)</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.357</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>2.388552</td>\n",
       "      <td>0.063947</td>\n",
       "      <td>4.365632</td>\n",
       "      <td>0.667436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>(Lipstick, Mascara)</td>\n",
       "      <td>(Eye shadow)</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>2.386065</td>\n",
       "      <td>0.063899</td>\n",
       "      <td>6.809000</td>\n",
       "      <td>0.660865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(Blush, Concealer, Mascara)</td>\n",
       "      <td>(Eye shadow)</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.908397</td>\n",
       "      <td>2.384244</td>\n",
       "      <td>0.069089</td>\n",
       "      <td>6.757417</td>\n",
       "      <td>0.668101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(Bronzer, Mascara)</td>\n",
       "      <td>(Eye shadow)</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.905109</td>\n",
       "      <td>2.375615</td>\n",
       "      <td>0.071803</td>\n",
       "      <td>6.523308</td>\n",
       "      <td>0.670981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          antecedents    consequents  antecedent support  \\\n",
       "0                           (Brushes)  (Nail Polish)               0.149   \n",
       "22     (Blush, Concealer, Eye shadow)      (Mascara)               0.124   \n",
       "5                 (Blush, Eye shadow)      (Mascara)               0.182   \n",
       "7           (Nail Polish, Eye shadow)      (Mascara)               0.131   \n",
       "12            (Concealer, Eye shadow)      (Mascara)               0.201   \n",
       "14              (Bronzer, Eye shadow)      (Mascara)               0.141   \n",
       "24  (Concealer, Eye shadow, Eyeliner)      (Mascara)               0.130   \n",
       "4                    (Blush, Mascara)   (Eye shadow)               0.184   \n",
       "18             (Lipstick, Eye shadow)      (Mascara)               0.129   \n",
       "17                (Lipstick, Mascara)   (Eye shadow)               0.121   \n",
       "21        (Blush, Concealer, Mascara)   (Eye shadow)               0.131   \n",
       "13                 (Bronzer, Mascara)   (Eye shadow)               0.137   \n",
       "\n",
       "    consequent support  support  confidence      lift  leverage  conviction  \\\n",
       "0                0.280    0.149    1.000000  3.571429  0.107280         inf   \n",
       "22               0.357    0.119    0.959677  2.688172  0.074732   15.946400   \n",
       "5                0.357    0.169    0.928571  2.601040  0.104026    9.002000   \n",
       "7                0.357    0.119    0.908397  2.544529  0.072233    7.019417   \n",
       "12               0.357    0.179    0.890547  2.494530  0.107243    5.874682   \n",
       "14               0.357    0.124    0.879433  2.463397  0.073663    5.333118   \n",
       "24               0.357    0.114    0.876923  2.456367  0.067590    5.224375   \n",
       "4                0.381    0.169    0.918478  2.410704  0.098896    7.593067   \n",
       "18               0.357    0.110    0.852713  2.388552  0.063947    4.365632   \n",
       "17               0.381    0.110    0.909091  2.386065  0.063899    6.809000   \n",
       "21               0.381    0.119    0.908397  2.384244  0.069089    6.757417   \n",
       "13               0.381    0.124    0.905109  2.375615  0.071803    6.523308   \n",
       "\n",
       "    zhangs_metric  \n",
       "0        0.846063  \n",
       "22       0.716895  \n",
       "5        0.752492  \n",
       "7        0.698504  \n",
       "12       0.749841  \n",
       "14       0.691567  \n",
       "24       0.681488  \n",
       "4        0.717137  \n",
       "18       0.667436  \n",
       "17       0.660865  \n",
       "21       0.668101  \n",
       "13       0.670981  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rules.sort_values(by=['lift'], ascending=False).head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eye shadow and mascara lead to each other alot. If we could get how well one leads to the other then we could try to use that as a more universal prior probability and clean up this ruleset to observe the relationships of the other products more. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
